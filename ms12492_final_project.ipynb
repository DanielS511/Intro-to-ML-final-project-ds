{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to ML Final Project\n",
    "Author: Daniel Sun  \n",
    "Date: 12/07/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import pickle as pkl\n",
    "from torchvision.models import resnet50, ResNet50_Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Device to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LazyLoadDataset(Dataset):\n",
    "  \"\"\"\n",
    "    Class for lazy loading \n",
    "    \n",
    "    Constructor:\n",
    "      path(String): the path in which lazy data are located\n",
    "      train(Boolean): the data is for train or not\n",
    "      transform(function): the function for us to perform transform on images\n",
    "  \"\"\"\n",
    "  def __init__(self, path, train=True, transform=None):\n",
    "    self.transform = transform\n",
    "    path = path + (\"train/\" if train else \"test/\")\n",
    "\n",
    "    self.pathX = path + \"X/\"\n",
    "    self.pathY = path + \"Y/\"\n",
    "\n",
    "    self.data = os.listdir(self.pathX)\n",
    "    self.train = train\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    f = self.data[idx]\n",
    "\n",
    "    img0 = cv2.imread(self.pathX + f + \"/rgb/0.png\")\n",
    "    img1 = cv2.imread(self.pathX + f + \"/rgb/1.png\")\n",
    "    img2 = cv2.imread(self.pathX + f + \"/rgb/2.png\")\n",
    "\n",
    "    if self.transform is not None:\n",
    "      img0 = self.transform(img0)\n",
    "      img1 = self.transform(img1)\n",
    "      img2 = self.transform(img2)\n",
    "    \n",
    "    depth = np.load(self.pathX + f + \"/depth.npy\")\n",
    "    # depth = self.transform(depth)\n",
    "\n",
    "    field_id = pkl.load(open(self.pathX + f + \"/field_id.pkl\", \"rb\"))\n",
    "\n",
    "    if self.train:\n",
    "      Y = np.load(self.pathY + f + \".npy\") * 1000\n",
    "      return (img0, img1, img2, depth), Y\n",
    "    else:\n",
    "      return (img0, img1, img2, depth)\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for normalization and transformation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomRotation(45),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        #transforms.Resize((224, 224)),#attention \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                            [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomRotation(45),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        #transforms.Resize((224, 224)),#attention \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                            [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define train and test dataset and dataloader\n",
    "train_dataset = LazyLoadDataset(\"./lazydata/\", transform=data_transforms['train'])\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=30, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, optimizer, permute_pixels=None, permutation_order=None):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch\n",
    "\n",
    "    Args:\n",
    "        epoch (int): current epoch\n",
    "        model (nn.Module): model to train\n",
    "        optimizer (torch.optim): optimizer to use\n",
    "        permute_pixels (function): function to permute the pixels (default: None)\n",
    "        permutation_order (1D torch array): order of the permutation (default: None)\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, ((img0, img1, img2, depth), target) in enumerate(train_loader):\n",
    "        # send to device\n",
    "        concate = torch.cat((img0, img1, img2, depth), dim=1)\n",
    "        data, target = concate.to(device), target.to(device)\n",
    "        \n",
    "        # permute pixels\n",
    "        if permute_pixels is not None:\n",
    "            data = permute_pixels(data, permutation_order)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        model = model.to(device)\n",
    "        output = model(data)\n",
    "        lossFn = nn.MSELoss()\n",
    "        loss = lossFn(output.float(), target.float())\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print('Train Epoch: {} \\tAvg Loss: {:.6f}'.format(\n",
    "                epoch, total_loss/len(train_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model for training\n",
    "# use resnet50 as a base\n",
    "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "model.float()\n",
    "model.fc = nn.Linear(2048, 12)\n",
    "weight = model.conv1.weight.clone()\n",
    "model.conv1 = nn.Conv2d(12, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "with torch.no_grad():\n",
    "    model.conv1.weight[:, :3] = weight\n",
    "    model.conv1.weight[:, 3] = model.conv1.weight[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 \tAvg Loss: 29.560263\n",
      "Train Epoch: 1 \tAvg Loss: 16.185776\n",
      "Train Epoch: 2 \tAvg Loss: 14.481716\n",
      "Train Epoch: 3 \tAvg Loss: 13.596376\n",
      "Train Epoch: 4 \tAvg Loss: 12.802649\n",
      "Train Epoch: 5 \tAvg Loss: 11.612081\n",
      "Train Epoch: 6 \tAvg Loss: 10.484567\n",
      "Train Epoch: 7 \tAvg Loss: 9.260120\n",
      "Train Epoch: 8 \tAvg Loss: 7.155323\n",
      "Train Epoch: 9 \tAvg Loss: 4.184078\n",
      "Train Epoch: 10 \tAvg Loss: 2.684620\n",
      "Train Epoch: 11 \tAvg Loss: 2.191308\n",
      "Train Epoch: 12 \tAvg Loss: 1.861231\n",
      "Train Epoch: 13 \tAvg Loss: 1.591500\n",
      "Train Epoch: 14 \tAvg Loss: 1.384787\n",
      "Train Epoch: 15 \tAvg Loss: 1.233111\n",
      "Train Epoch: 16 \tAvg Loss: 1.129283\n",
      "Train Epoch: 17 \tAvg Loss: 1.041603\n",
      "Train Epoch: 18 \tAvg Loss: 0.966110\n",
      "Train Epoch: 19 \tAvg Loss: 0.906252\n",
      "Train Epoch: 20 \tAvg Loss: 0.852666\n",
      "Train Epoch: 21 \tAvg Loss: 0.805656\n",
      "Train Epoch: 22 \tAvg Loss: 0.766693\n",
      "Train Epoch: 23 \tAvg Loss: 0.731094\n",
      "Train Epoch: 24 \tAvg Loss: 0.692568\n",
      "Train Epoch: 25 \tAvg Loss: 0.661462\n",
      "Train Epoch: 26 \tAvg Loss: 0.629905\n",
      "Train Epoch: 27 \tAvg Loss: 0.601338\n",
      "Train Epoch: 28 \tAvg Loss: 0.578940\n",
      "Train Epoch: 29 \tAvg Loss: 0.556215\n",
      "Train Epoch: 30 \tAvg Loss: 0.542907\n",
      "Train Epoch: 31 \tAvg Loss: 0.531284\n",
      "Train Epoch: 32 \tAvg Loss: 0.511958\n",
      "Train Epoch: 33 \tAvg Loss: 0.489195\n",
      "Train Epoch: 34 \tAvg Loss: 0.469190\n",
      "Train Epoch: 35 \tAvg Loss: 0.448150\n",
      "Train Epoch: 36 \tAvg Loss: 0.431364\n",
      "Train Epoch: 37 \tAvg Loss: 0.416190\n",
      "Train Epoch: 38 \tAvg Loss: 0.400726\n",
      "Train Epoch: 39 \tAvg Loss: 0.388667\n"
     ]
    }
   ],
   "source": [
    "# define the optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# train the model for 40 epoches\n",
    "for epoch in range(0, 40):\n",
    "    train(epoch, model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Test Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written to csv file submission.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "outfile = 'submission.csv'\n",
    "\n",
    "output_file = open(outfile, 'w')\n",
    "\n",
    "titles = ['ID', 'FINGER_POS_1', 'FINGER_POS_2', 'FINGER_POS_3', 'FINGER_POS_4', 'FINGER_POS_5', 'FINGER_POS_6',\n",
    "         'FINGER_POS_7', 'FINGER_POS_8', 'FINGER_POS_9', 'FINGER_POS_10', 'FINGER_POS_11', 'FINGER_POS_12']\n",
    "preds = []\n",
    "\n",
    "test_data = torch.load('./test/test/testX.pt')\n",
    "file_ids = test_data[-1]\n",
    "rgb_data = test_data[0]\n",
    "depth = test_data[1]\n",
    "model.eval()\n",
    "\n",
    "for i, (img0, img1, img2) in enumerate(rgb_data):\n",
    "\n",
    "    img0 = data_transforms['test'](img0)\n",
    "    img1 = data_transforms['test'](img1)\n",
    "    img2 = data_transforms['test'](img2)\n",
    "    \n",
    "    data = torch.cat((img0, img1, img2, depth[i]), dim=0)\n",
    "    data = torch.unsqueeze(data, 0)\n",
    "    output = model(data.to(device)) / 1000\n",
    "    preds.append(output[0].cpu().detach().numpy())\n",
    "\n",
    "df = pd.concat([pd.DataFrame(file_ids), pd.DataFrame.from_records(preds)], axis = 1, names = titles)\n",
    "df.columns = titles\n",
    "df.to_csv(outfile, index = False)\n",
    "print(\"Written to csv file {}\".format(outfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The public score of the prediction on Kaggle is 0.00551"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lazy loading can save a lot of time\n",
    "- It is also memory friendly\n",
    "- Large batch size can result in memory shortage so decreases batch size to save GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Normalization on RGB images can improve the performance of the model tremendously\n",
    "- Possibly because some of the data are very large compare to the other ones\n",
    "- It is very useful to multiple the Y by 1000 when loading the data as the Y is smaller than X\n",
    "- Transform depth image doesn't improve the performance much"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using pre-trained model(like resnet50 in this case) can provide a good start\n",
    "- Need to modify the fc layer of the model to accomadate the data\n",
    "- SGD optimizer in my case perform better than Adam optimizer\n",
    "- Running multiple epoches can improve the model tremendously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Trying different normalization methods to see if we can achieve a better result\n",
    "- Trying more optimizers or modifying optimizers' parameters like learning rate\n",
    "- Using other pre-trained or self-defined models \n",
    "- Running the model for more epoches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98df1a0825261fa5da2004b0c92c481089275adf1d4b1391f737350e394b16e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
